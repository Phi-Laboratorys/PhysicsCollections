\iffalse \begin{enumerate}
	\item Recheneigenschaften von Vektoren und Skalaren
	\item Koordinatentransformationen
	\item Rechenregeln von Matrizen
	\item Determinante mit Rechenregeln
	\item Eigenwerte und Eigenvektoren
	\item Eulersche Formel
	\item Taylorreihe
	\item Fourier Reihe
	\item Dirac Delta Funktion
	\item Fourier Transformation
\end{enumerate}\fi

\section{Skalare, Vektoren und Matrizen}

Ein Skalar $a$ ist eine gewöhnliche Zahl aus einem beliebigen Körper (z.B. $\R$ oder $\C$). Ein Vektor $\mathbf{a}$ ist ein Element eines Vektorraums (z.B. $\R^3$). Eine Matrix $\bf{A}$ besteht aus $n$ Spalten und $m$ Reihen (also $\mathbf{A} \in \R^{m\times n}$). Im Folgenden wird nur der dreidimensionale Vektorraum $\R^3$ betrachtet.

Für den Betrag gilt $a = |\mathbf{a}| = \sqrt{a_1^2 + a_2^2 + a_3^2}$. Der nomierte Vektor $\mathbf{\hat{a}} = \frac{1}{|\mathbf{a}|} \mathbf{a}$ hat immer die Länge 1. 

\begin{frameddefn}[Skalarprodukt]
	\[\mathbf{a}\cdot \mathbf{b} = a_1 b_1 + a_2 b_2 + a_3 b_3\]
\end{frameddefn}

Es gilt:

\begin{itemize}
	\item $\mathbf{a}\cdot \mathbf{b} = a\, b \cos\alpha$, wenn $\alpha$ der Winkel zwischen $\mathbf{a}$ und $\mathbf{b}$ ist.
	\item $\mathbf{a}\cdot \mathbf{b} = \mathbf{b}\cdot \mathbf{a}$
	\item $(\lambda \mathbf{a})\cdot \mathbf{b} = \lambda (\mathbf{a}\cdot \mathbf{b}) = \mathbf{a}\cdot ( \lambda \mathbf{b})$
	\item $\mathbf{a}\cdot (\mathbf{b} + \mathbf{c}) = \mathbf{a}\cdot \mathbf{b} + \mathbf{a}\cdot \mathbf{c}$
	\item $\mathbf{a}\cdot \mathbf{b} = 0 \ \iff\ \mathbf{a}\perp \mathbf{b}$
\end{itemize}

\begin{frameddefn}[Kreuzprodukt]
	\[\mathbf{a}\times \mathbf{b} = 
	\left(\begin{array}{c} a_1 \\ a_2 \\ a_3 \end{array}  \right) \times \left(\begin{array}{c} b_1 \\ b_2 \\ b_3 \end{array}  \right) =
	\left(\begin{array}{c} a_2 b_3 - a_3 b_2 \\ a_3 b_1 - a_1 b_3\\ a_1 b_2 - a_2 b_1 \end{array}  \right)\]
\end{frameddefn}

\begin{frameddefn}[Spatprodukt]
	\[(\mathbf{a} \times \mathbf{b}) \cdot \mathbf{c} \]
	Gibt das Volumen, das durch die drei Vektoren aufgespannt wird an.
\end{frameddefn}

\begin{frameddefn}[Matrix ($3\times 3$)]
	\[\mathbf{A} = (a_{ij}) = \left(\begin{array}{rrr} 
		a_{11} & a_{12} & a_{13} \\ 
		a_{21} & a_{22} & a_{23} \\ 
		a_{31} & a_{32} & a_{33} \\ 
	\end{array}\right)\]
\end{frameddefn}

\begin{frameddefn}[Matrixmultiplikation]
	\[\mathbf{A} \cdot \mathbf{B} = \mathbf{C} = (c_{ik}) = \sum_{j=1}^{3} a_{ij} b_{jk}\]
	Der Eintrag in der $i$-ten Reihe und $k$-ten Spalte in $\mathbf{C}$ ist das Skalarprodukt der $i$-ten Reihe der Matrix $\mathbf{A}$ und der $k$-ten Spalte der Matrix $\mathbf{B}$.\\
	\textbf{Hinweis:} $\mathbf{A}$ muss von der Form $m \times n$ und $\mathbf{B}$ von der Form $n \times p$ sein. $\mathbf{C}$ hat dann die Form $m \times p$.
\end{frameddefn}

\begin{frameddefn}[Dyadisches Produkt]
	\[\mathbf{a}\mathbf{b} = \mathbf{a} \cdot \mathbf{b}^t = 
	\left(\begin{array}{rrr} 
		x_1 y_1 & x_1 y_2 & x_1 y_3 \\ 
		x_2 y_1 & x_2 y_2 & x_2 y_3 \\ 
		x_3 y_1 & x_3 y_2 & x_3 y_3 \\ 
	\end{array}\right)
	\]
\end{frameddefn}

\begin{frameddefn}[Inverse einer Matrix]
	Eine Matrix $\mathbf{A}^{-1}$ heißt Inverse einer quadratischen Matrix $\mathbf{A}$, wenn $\mathbf{A} \cdot \mathbf{A}^{-1} = \mathbb{I}$
\end{frameddefn}

Es gilt:
\begin{itemize}
	\item $\mathbf{A} + \mathbf{B} = 
	\left(\begin{array}{rrr} 
		a_{11} & a_{12} & a_{13} \\ 
		a_{21} & a_{22} & a_{23} \\ 
		a_{31} & a_{32} & a_{33} \\ 
	\end{array}\right) +
	\left(\begin{array}{rrr} 
		b_{11} & b_{12} & b_{13} \\ 
		b_{21} & b_{22} & b_{23} \\ 
		b_{31} & b_{32} & b_{33} \\ 
	\end{array}\right) = 
	\left(\begin{array}{rrr} 
		a_{11} + b_{11} & a_{12} + b_{12} & a_{13} + b_{13} \\ 
		a_{21} + b_{21} & a_{22} + b_{22} & a_{23} + b_{23} \\ 
		a_{31} + b_{31} & a_{32} + b_{32} & a_{33} + b_{33} \\ 
	\end{array}\right)$

	\item $\alpha \mathbf{A} = \left(\begin{array}{rrr} 
		\alpha a_{11} & \alpha a_{12} & \alpha a_{13} \\ 
		\alpha a_{21} & \alpha a_{22} & \alpha a_{23} \\ 
		\alpha a_{31} & \alpha a_{32} & \alpha a_{33} \\ 
	\end{array}\right)$

	\item Transposition: $\mathbf{A}^t = 
	\left(\begin{array}{rrr} 
		a_{11} & a_{12} & a_{13} \\ 
		a_{21} & a_{22} & a_{23} \\ 
		a_{31} & a_{32} & a_{33} \\ 
	\end{array}\right)^t = 
	\left(\begin{array}{rrr} 
		a_{11} & a_{21} & a_{31} \\ 
		a_{12} & a_{22} & a_{32} \\ 
		a_{13} & a_{23} & a_{33} \\ 
	\end{array}\right)$

	\item $\mathbf{A} \cdot (\mathbf{B} \cdot \mathbf{C}) = (\mathbf{A} \cdot \mathbf{B}) \cdot \mathbf{C}$
	
	\item $\mathbf{A} \cdot (\mathbf{B} + \mathbf{C}) = \mathbf{A} \cdot \mathbf{B} + \mathbf{A} \cdot \mathbf{C}$
	
	\item im Allgemeinen: $\mathbf{A} \cdot \mathbf{B} \neq \mathbf{B} \cdot \mathbf{A}$
	
	\item $(\mathbf{A} \cdot \mathbf{B})^{-1} = \mathbf{B}^{-1} \cdot \mathbf{A}^{-1}$
	
\end{itemize}

\section{Determinante}

\begin{frameddefn}[Entwicklung nach erster Zeile]
	Sei $\mathbf{A} = (a_{ij}) \in \C^{n\times n}$.
	\[
	\det(\mathbf{A}) = \sum_{k=1}^{n} (-1)^{1+k} a_{1k} \det(\mathbf{A}_{1k})
	\]
	wobei $\mathbf{A}_{jk}$ die Matrix $\mathbf{A}$ ist, bei der die $j$-te Zeile und $k$-te Spalte entfernt wurden (also $\mathbf{A}_{jk} \in \C^{(n-1) \times (n-1)}$).
\end{frameddefn}

\begin{framedthm}[Regel von Sarrus für $3 \times 3$ Matrizen]
	\[
	\det(\mathbf{A}) = a_{11} a_{22} a_{33} + a_{12} a_{23} a_{31} + a_{13} a_{21} a_{32} - a_{13} a_{22} a_{31} - a_{11} a_{23} a_{32} - a_{12} a_{21} a_{33}
	\]
\end{framedthm}

\todo{Eigenschaften von Determinanten}

\begin{framedprop}[Entwicklung nach beliebiger Zeile oder Spalte]
	Entwicklung nach $k$-ter Zeile:
	\[
	\det(\mathbf{A}) = \sum_{j=1}^{n} (-1)^{k-j} a_{kj} \det(\mathbf{A}_{kj})
	\]
	Entwicklung nach $k$-ter Spalte:
	\[
	\det(\mathbf{A}) = \sum_{i=1}^{n} (-1)^{i-k} a_{ik} \det(\mathbf{A}_{ik})
	\]
	\textbf{Hinweis:} Wenn $k$ ungerade wird mit einem positiven Vorzeichen angefangen, welches dann alterniert wird. Wenn $k$ gerade wird mit einem negativen Vorzeichen angefangen und dann alterniert.
\end{framedprop}

\begin{framedthm}[Multiplikationstheorem]
	Sei $\mathbf{C} = \mathbf{A} \cdot \mathbf{B}$. Dann gilt: $\det(\mathbf{C})= \det(\mathbf{A}\cdot\mathbf{B}) = \det(\mathbf{A}) \det(\mathbf{B})$.
\end{framedthm}

\newpage
\section{Eigenwerte und Eigenvektoren}

\begin{frameddefn}[Eigenwerte und Eigenvektoren]
	$\lambda$ heißt Eigenwert zu einem Eigenvektor $\mathbf{x}$, wenn $\mathbf{x} \neq 0$ und $\mathbf{A} \cdot \mathbf{x} = \lambda \mathbf{x}$.
\end{frameddefn}

\begin{framedprop}[Charakteristisches Polynom]
	\[\chi_n(\lambda) = \det(\mathbf{A}-\lambda \mathbb{I}) \]
	Die Eigenwerte $\lambda_i$ sind die Nullstellen des charakteristischen Polynoms. Es gibt $n$ Eigenwerte, die jedoch auch komplex und entartet ($\lambda_i = \lambda_j$ für $i\neq j$) sein können. Zu jedem Eigenwert gibt es einen Eigenvektor $\mathbf{x}_i$.
\end{framedprop}

\section{Totale Ableitung}

\begin{framedprop}[Totale Ableitung einer Funktion]
\[
\frac{\dd f(x_1(t), ..., x_n(t), t)}{\dd t} = \frac{\partial f}{\partial x_1} \frac{\dd x_1}{\dd t} + ... + \frac{\partial f}{\partial x_n} \frac{\dd x_n}{\dd t} + \frac{\partial f}{\partial t}
\]
\end{framedprop}

\section{Taylorreihe}

\begin{framedprop}[Taylorreihe]
	\[
	T_{N, f}(x; x_0) = \sum_{k=0}^{N} \frac{f^{(k)}(x_0)}{k!} (x-x_0)^k
	\]
\end{framedprop}

\begin{framedprop}[Taylorentwicklung in mehreren Variablen]
	\[
	T_{f(x,y)} = \sum_{n=0}^{\infty} \sum_{m=0}^{\infty} \frac{\partial^n}{\partial x^n} \frac{\partial^m}{\partial y^m} f \bigg|_{(x_0,y_0)} \frac{1}{n!m!} (x-x_0)^n (y-y_0)^m
	\]
\end{framedprop}


\section{Fourier Reihen}

\begin{framedprop}[Fourier Reihe]
	Meistens ist $L = \pi$. Dann ist die Fourier Reihe von $f$:
	\[
	f(x) = \sum_{n=-\infty}^{\infty} c_n \exp\left(\frac{inx \pi}{L}\right) \qquad \textrm{ mit }
	c_n = \frac{1}{2L} \int_{-L}^{L} \dd x \, f(x) \, \exp\left(\frac{-inx \pi}{L}\right)
	\]
\end{framedprop}

\section{Dirac-Delta-Funktion}

\begin{frameddefn}[Als Ableitung der Stufenfunktion $\Theta$]
	\[\delta(x) = \frac{\dd}{\dd x}\Theta(x)\]
\end{frameddefn}

\begin{frameddefn}[Als Limes einer geeigneten Funktionenschar]
	\[
	\delta(x) = \lim\limits_{\tau \to 0} \delta_{\tau}(x)
	\]
\end{frameddefn}

\begin{frameddefn}[Durch integrale Eigenschaft]
	\[
	\int_{x_1}^{x_2} \dd x\, \delta(x-x_0)\, g(x) = \biggl\{\begin{array}{ll}
		g(x_0) \ \ \ \textrm{falls}\  x_1 < x_0 < x_2 \\
		0, \  \textrm{sonst}
	\end{array}
	\]
\end{frameddefn}

Rechenregeln:
\begin{itemize}
	\item Gerade Funktion: $\delta(x) = \delta(-x)$
	\item $\delta(x-x_0) = \delta(x_0 - x)$
	\item $\delta(\alpha x) = \frac{1}{|\alpha|} \delta(x)$
	\item $\delta(f(x)) = \sum_{i} \frac{1}{|f'(x_i)|} \delta(x-x_i)$ wobei $x_i$ die Nullstellen von $f$ sind. (Es muss $f'(x_i) \neq 0$ gelten)
\end{itemize}

\section{Fourier Transformation}

\begin{framedprop}[Fourier Transformation]
	Transformation in reziproken Raum (Fourier Raum):
	\[
	\tilde{f}(k) = \int_{-\infty}^{\infty} \dd x\, f(x)\, e^{-ikx} =: \mathcal{F}\, f(x)
	\]
	Rücktransformation:
	\[
	f(x) = \frac{1}{2\pi} \int_{-\infty}^{\infty} \dd k\, \tilde{f}(k)\, e^{+ikx} =: \mathcal{F}^{-1}\, \tilde{f}(k)
 	\]
\end{framedprop}

Eigenschaften:
\begin{itemize}
	\item Linearität: $\mathcal{F}(a f(x) + b g(x)) = a\, \mathcal{F}\, f(x) + b\, \mathcal{F}\, g(x)$
	\item Identität: $(\mathcal{F}^{-1}\,\circ \mathcal{F}) f(x) = f(x)$
	\item Differentiation: $\frac{\dd}{\dd x}f = \mathcal{F}^{-1}\, ik\, \mathcal{F}\, f(x)$
	\item Faltung: $(f \star g)(x) = \int_{-\infty}^{\infty} \dd x' f(x') g(x - x') = \tilde{f}(k)\tilde{g}(k)$
	\item Verschobene Funktion: Sei $g(x) = f(x-x_0)$. Dann: $\tilde{g}(k) = \exp(-ikx_0)\tilde{f}(k)$
\end{itemize}

\begin{framedprop}[Mehrdimensionale Fourier-Transformation]
Seien $\mathbf{r}, \mathbf{k} \in \R^d$.
\[
\tilde{f}(\mathbf{k}) = \int_{\R^d} \dd\mathbf{r}\, f(\mathbf{r})\, e^{-i\,\mathbf{k}\cdot\mathbf{r}}
\]
\[
f(\mathbf{r}) = \frac{1}{(2\pi)^d} \int_{\R^d} \dd\mathbf{k}\, \tilde{f}(\mathbf{k})\, e^{i\,\mathbf{k}\cdot\mathbf{r}}
\]
	
\end{framedprop}